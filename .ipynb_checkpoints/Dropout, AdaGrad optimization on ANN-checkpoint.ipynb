{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "32cfdf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2aeffe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "80a12656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.cuda.device at 0x210aa8639d0>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_gpus = [torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
    "available_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "866b96c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'trainingSet'\n",
    "image_list = []\n",
    "labels = []\n",
    "list_folders = os.listdir(directory)\n",
    "for folders in list_folders:\n",
    "    images = os.listdir(f'{directory}/{folders}')\n",
    "    for image in images:\n",
    "        image_dir = f'{directory}/{folders}/{image}'\n",
    "        image_list.append(image_dir)\n",
    "        labels.append(folders)\n",
    "        \n",
    "\n",
    "#randomizing the dataset\n",
    "image_list = np.array(image_list)\n",
    "labels = np.array(labels)\n",
    "randomize = np.arange(len(labels))\n",
    "np.random.shuffle(randomize)\n",
    "image_list = image_list[randomize]\n",
    "labels = labels[randomize]\n",
    "\n",
    "#splitting the dataset into training and testing part\n",
    "train_image_list = image_list[0:int(len(image_list)*0.9)]\n",
    "test_image_list = image_list[int(len(image_list)*0.9):]\n",
    "train_labels = labels[0:int(len(image_list)*0.9)]\n",
    "test_labels = labels[int(len(image_list)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e43d6ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(img):\n",
    "    img = np.array(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    y, u, v = cv2.split(img)\n",
    "    y = y / 255.0\n",
    "    x = np.array(y.flatten()).reshape(1,784)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ce885334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activation Functions\n",
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    maxes = torch.max(x, 1, keepdim=True)[0]\n",
    "    x_exp = torch.exp(x-maxes)\n",
    "    x_exp_sum = torch.sum(x_exp, 1, keepdim=True)\n",
    "    return x_exp/x_exp_sum\n",
    "\n",
    "def tanh(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "def relu(x):\n",
    "    return x * (x > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f41dfcd",
   "metadata": {},
   "source": [
    " # Network with 5 Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5cf14e",
   "metadata": {},
   "source": [
    "## 1. Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "00bcda72",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = 784\n",
    "hidden_layer1 = 392\n",
    "hidden_layer2 = 196\n",
    "hidden_layer3 = 64\n",
    "hidden_layer4 = 32\n",
    "output_layer = 10\n",
    "\n",
    "def initialize_weights_and_bias(mode, distribution='uniform'):\n",
    "    '''\n",
    "    Initialize weights and bias for neural network layers using the specified distribution. \n",
    "    '''\n",
    "\n",
    "    if mode == 'random':\n",
    "        W1 = np.random.random((hidden_layer1, input_layer)).astype(np.float32)   #784x392\n",
    "        b1 = np.random.random((1, hidden_layer1)).astype(np.float32)             #1x392\n",
    "        W2 = np.random.random((hidden_layer1, hidden_layer2)).astype(np.float32) #392x196\n",
    "        b2 = np.random.random((1, hidden_layer2)).astype(np.float32)             #1x196\n",
    "        W3 = np.random.random((hidden_layer2, hidden_layer3)).astype(np.float32) #196x64\n",
    "        b3 = np.random.random((1, hidden_layer3)).astype(np.float32)             #1x64\n",
    "        W4 = np.random.random((hidden_layer3, hidden_layer4)).astype(np.float32) #64x32\n",
    "        b4 = np.random.random((1, hidden_layer4)).astype(np.float32)             #1x32\n",
    "        W5 = np.random.random((hidden_layer4, output_layer)).astype(np.float32)  #32x10\n",
    "        b5 = np.random.random((1, output_layer)).astype(np.float32)              #1x10\n",
    "    elif mode == 'xavier':\n",
    "        if distribution == 'normal':\n",
    "            W1 = np.random.normal(loc=0.0, scale=np.sqrt(2/(hidden_layer1 + input_layer)), size=((hidden_layer1, input_layer))).astype(np.float32)    #784x392\n",
    "            b1 = np.random.normal(loc=0.0, scale=np.sqrt(2/(1+hidden_layer1)), size=((1, hidden_layer1))).astype(np.float32)              #1x392   \n",
    "            W2 = np.random.normal(loc=0.0, scale=np.sqrt(2/(hidden_layer1 + hidden_layer2)), size=((hidden_layer1, hidden_layer2))).astype(np.float32)  #392x196\n",
    "            b2 = np.random.normal(loc=0.0, scale=np.sqrt(2/(1 + hidden_layer2)), size=((1, hidden_layer2))).astype(np.float32)              #1x196\n",
    "            W3 = np.random.normal(loc=0.0, scale=np.sqrt(2/(hidden_layer2 + hidden_layer3)), size=((hidden_layer2, hidden_layer3))).astype(np.float32)  #196x64\n",
    "            b3 = np.random.normal(loc=0.0, scale=np.sqrt(2/(1 + hidden_layer3)), size=((1, hidden_layer3))).astype(np.float32)              #1x64\n",
    "            W4 = np.random.normal(loc=0.0, scale=np.sqrt(2/(hidden_layer3 + hidden_layer4)), size=((hidden_layer3, hidden_layer4))).astype(np.float32)  #64x32\n",
    "            b4 = np.random.normal(loc=0.0, scale=np.sqrt(2/(1 + hidden_layer4)), size=((1, hidden_layer4))).astype(np.float32)              #1x32\n",
    "            W5 = np.random.normal(loc=0.0, scale=np.sqrt(2/(hidden_layer4 + output_layer)), size=((hidden_layer4, output_layer))).astype(np.float32)   #32x10\n",
    "            b5 = np.random.normal(loc=0.0, scale=np.sqrt(2/(1 + output_layer)), size=((1, output_layer))).astype(np.float32)               #1x10\n",
    "        elif distribution == 'uniform':\n",
    "            W1 = np.random.uniform(low = -np.sqrt(6/(hidden_layer1 + input_layer)), high = np.sqrt(6/(hidden_layer1 + input_layer)), size=((hidden_layer1, input_layer))).astype(np.float32)   #392x784\n",
    "            b1 = np.random.uniform(low = -np.sqrt(6/(1+hidden_layer1)), high = np.sqrt(6/(1+hidden_layer1)), size=((1, hidden_layer1))).astype(np.float32)             #1x392\n",
    "            W2 = np.random.uniform(low = -np.sqrt(6/(hidden_layer1 + hidden_layer2)), high = np.sqrt(6/(hidden_layer1 + hidden_layer2)), size=((hidden_layer2, hidden_layer1))).astype(np.float32) #392x196\n",
    "            b2 = np.random.uniform(low = -np.sqrt(6/(1 + hidden_layer2)), high = np.sqrt(6/(1 + hidden_layer2)), size=((1, hidden_layer2))).astype(np.float32)             #1x196\n",
    "            W3 = np.random.uniform(low = -np.sqrt(6/(hidden_layer2 + hidden_layer3)), high = np.sqrt(6/(hidden_layer2 + hidden_layer3)), size=((hidden_layer3, hidden_layer2))).astype(np.float32) #196x64\n",
    "            b3 = np.random.uniform(low = -np.sqrt(6/(1 + hidden_layer3)), high = np.sqrt(6/(1 + hidden_layer3)), size=((1, hidden_layer3))).astype(np.float32)             #1x64\n",
    "            W4 = np.random.uniform(low = -np.sqrt(6/(hidden_layer3 + hidden_layer4)), high = np.sqrt(6/(hidden_layer3 + hidden_layer4)), size=((hidden_layer4, hidden_layer3))).astype(np.float32) #64x32\n",
    "            b4 = np.random.uniform(low = -np.sqrt(6/(1 + hidden_layer4)), high = np.sqrt(6/(1 + hidden_layer4)), size=((1, hidden_layer4))).astype(np.float32)             #1x32\n",
    "            W5 = np.random.uniform(low = -np.sqrt(6/(hidden_layer4 + output_layer)), high = np.sqrt(6/(hidden_layer4 + output_layer)), size=((output_layer, hidden_layer4))).astype(np.float32)  #32x10\n",
    "            b5 = np.random.uniform(low = -np.sqrt(6/(1 + output_layer)), high = np.sqrt(6/(1 + output_layer)), size=((1, output_layer))).astype(np.float32)              #1x10\n",
    "    elif mode == 'constant':\n",
    "        W1 = np.ones((hidden_layer1, input_layer)).astype(np.float32)     #784x392\n",
    "        b1 = np.ones((1, hidden_layer1)).astype(np.float32)               #1x392\n",
    "        W2 = np.ones((hidden_layer1, hidden_layer2)).astype(np.float32)   #392x196\n",
    "        b2 = np.ones((1, hidden_layer2)).astype(np.float32)               #1x196\n",
    "        W3 = np.ones((hidden_layer2, hidden_layer3)).astype(np.float32)   #196x64\n",
    "        b3 = np.ones((1, hidden_layer3)).astype(np.float32)               #1x64\n",
    "        W4 = np.ones((hidden_layer3, hidden_layer4)).astype(np.float32)   #64x32\n",
    "        b4 = np.ones((1, hidden_layer4)).astype(np.float32)               #1x32 \n",
    "        W5 = np.ones((hidden_layer4, output_layer)).astype(np.float32)    #32x10\n",
    "        b5 = np.ones((1, output_layer)).astype(np.float32)                #1x10\n",
    "    elif mode == 'zero':\n",
    "        W1 = np.zeros((hidden_layer1, input_layer)).astype(np.float32)\n",
    "        b1 = np.zeros((1, hidden_layer1)).astype(np.float32)\n",
    "        W2 = np.zeros((hidden_layer1, hidden_layer2)).astype(np.float32)\n",
    "        b2 = np.zeros((1, hidden_layer2)).astype(np.float32)\n",
    "        W3 = np.zeros((hidden_layer2, hidden_layer3)).astype(np.float32)\n",
    "        b3 = np.zeros((1, hidden_layer3)).astype(np.float32)\n",
    "        W4 = np.zeros((hidden_layer3, hidden_layer4)).astype(np.float32)\n",
    "        b4 = np.zeros((1, hidden_layer4)).astype(np.float32)\n",
    "        W5 = np.zeros((hidden_layer4, output_layer)).astype(np.float32)\n",
    "        b5 = np.zeros((1, output_layer)).astype(np.float32)\n",
    "    else:\n",
    "        print('Error: mode not recognized')\n",
    "        return\n",
    "    \n",
    "\n",
    "    return W1, b1, W2, b2, W3, b3, W4, b4, W5, b5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d39313cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(x, W1, b1, W2, b2, W3, b3, W4, b4, W5, b5):\n",
    "    \n",
    "    #First layer\n",
    "    x = np.array(x, dtype=np.float32)                 #784x1\n",
    "    x = torch.from_numpy(x)\n",
    "    x.to('cuda')\n",
    "    \n",
    "    res1 = torch.mm(x, W1.T) + b1                    #392x1\n",
    "    layer1_out = sigmoid(res1)                        #392x1\n",
    "    # print(layer1_out)                 \n",
    "    \n",
    "    #Second layer\n",
    "    res2 = torch.mm(layer1_out, W2.T) + b2          #196x1\n",
    "    layer2_out = sigmoid(res2)                       #196x1\n",
    "    #print(layer2_out)                                \n",
    "    \n",
    "    #Third layer\n",
    "    res3 = torch.mm(layer2_out, W3.T) + b3         #64x1\n",
    "    layer3_out = sigmoid(res3)                      #64x1\n",
    "    #print(layer3_out)\n",
    "    \n",
    "    #Fourth Layer\n",
    "    res4 = torch.mm(layer3_out, W4.T) + b4        #32x1\n",
    "    layer4_out = sigmoid(res4)                     #32x1\n",
    "    #print(layer4_out)\n",
    "    \n",
    "    #Fifth Layer\n",
    "    res5 = torch.mm(layer4_out, W5.T) + b5        #10x1\n",
    "    layer5_out = softmax(res5)                     #10x1\n",
    "    #print(layer5_out)\n",
    "    \n",
    "    \n",
    "    return layer1_out.flatten(), layer2_out.flatten(), layer3_out.flatten(), layer4_out.flatten(), layer5_out.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "40a4c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(x, y, W1, b1, W2, b2, W3, b3, W4, b4, W5, b5, z1, z2, z3, z4, y_hat):\n",
    "    \n",
    "    x = np.array(x, dtype= np.float32).reshape(1,784)\n",
    "    y = np.array(y, dtype = np.float32).reshape(1,10)\n",
    "    y_hat = np.array(y_hat, dtype=np.float32).reshape(1,10)\n",
    "    z1 = np.array(z1, dtype=np.float32).reshape(1, 392)\n",
    "    z2 = np.array(z2, dtype=np.float32).reshape(1, 196)\n",
    "    z3 = np.array(z3, dtype=np.float32).reshape(1, 64)\n",
    "    z4 = np.array(z4, dtype=np.float32).reshape(1, 32)\n",
    "\n",
    "    #converting the arrays to tensors\n",
    "    x = torch.from_numpy(x)\n",
    "    y = torch.from_numpy(y)\n",
    "    y_hat = torch.from_numpy(y_hat)\n",
    "    z1 = torch.from_numpy(z1)\n",
    "    z2 = torch.from_numpy(z2)\n",
    "    z3 = torch.from_numpy(z3)\n",
    "    z4 = torch.from_numpy(z4)\n",
    "\n",
    "    #allocating the memory in device for our tensors\n",
    "    x.to('cuda')\n",
    "    y.to('cuda')\n",
    "    y_hat.to('cuda')\n",
    "    z1.to('cuda')\n",
    "    z2.to('cuda')\n",
    "    z3.to('cuda')\n",
    "    z4.to('cuda')\n",
    "\n",
    "\n",
    "    \n",
    "    #Final Layer\n",
    "    db5 = (y_hat-y)                                              \n",
    "    dw5 = torch.mm(db5.T, z4)                                         \n",
    "    \n",
    "    #Fourth Layer\n",
    "    db4 = torch.mm(torch.mm(torch.mm(db5, W5).T, z4), (1-z4).T).T   \n",
    "    dw4 = torch.mm(db4.T, z3)                                         \n",
    "    \n",
    "    #Third Layer\n",
    "    db3 = torch.mm(torch.mm(torch.mm(db4, W4).T, z3), (1-z3).T).T   \n",
    "    dw3 = torch.mm(db3.T, z2)                                        \n",
    "    \n",
    "    #Second Layer\n",
    "    db2 = torch.mm(torch.mm(torch.mm(db3, W3).T, z2), (1-z2).T).T   \n",
    "    dw2 = torch.mm(db2.T, z1) \n",
    "\n",
    "    #First Layer\n",
    "    db1 = torch.mm(torch.mm(torch.mm(db2, W2).T, z1), (1-z1).T).T   \n",
    "    dw1 = torch.mm(db1.T, x) \n",
    "\n",
    "\n",
    "    return dw1, db1, dw2, db2, dw3, db3, dw4, db4, dw5, db5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dd23ba",
   "metadata": {},
   "source": [
    "## Now the Training Begins with MiniBatch Gradient with AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f198b08f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [104]\u001b[0m, in \u001b[0;36m<cell line: 35>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m     tb4 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39madd(tb4, db4)\n\u001b[0;32m    120\u001b[0m     tW5 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39madd(tW5, dW5\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m--> 121\u001b[0m     tb5 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtb5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m#take average\u001b[39;00m\n\u001b[0;32m    124\u001b[0m tW1 \u001b[38;5;241m=\u001b[39m tW1\u001b[38;5;241m/\u001b[39mbatch_size\n",
      "\u001b[1;31mTypeError\u001b[0m: add(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "W1, b1, W2, b2, W3, b3, W4, b4, W5, b5 = initialize_weights_and_bias(mode='xavier', distribution='uniform')\n",
    "W1 = torch.from_numpy(W1)\n",
    "W1.to('cuda')\n",
    "b1 = torch.from_numpy(b1)\n",
    "b1.to('cuda')\n",
    "W2 = torch.from_numpy(W2)\n",
    "W2.to('cuda')\n",
    "b2 = torch.from_numpy(b2)\n",
    "b2.to('cuda')\n",
    "W3 = torch.from_numpy(W3)\n",
    "W3.to('cuda')\n",
    "b3 = torch.from_numpy(b3)\n",
    "b3.to('cuda')\n",
    "W4 = torch.from_numpy(W4)\n",
    "W4.to('cuda')\n",
    "b4 = torch.from_numpy(b4)\n",
    "b4.to('cuda')\n",
    "W5 = torch.from_numpy(W5)\n",
    "W5.to('cuda')\n",
    "\n",
    "target = np.array(train_labels)\n",
    "# target = torch.from_numpy(target)\n",
    "# target.to('cuda')\n",
    "\n",
    "cost = 0\n",
    "losses = []\n",
    "epochs = 10\n",
    "batch_size = 200\n",
    "epsilon = 10e-8\n",
    "lr = 0.1\n",
    "\n",
    "for j in range(epochs):\n",
    "    losss = 0\n",
    "    tp = 0\n",
    "    \n",
    "    VW1, Vb1, VW2, Vb2, VW3, Vb3, VW4, Vb4, VW5, Vb5 = initialize_weights_and_bias(mode='zero')\n",
    "    VW1 = torch.from_numpy(VW1)\n",
    "    VW1.to('cuda')\n",
    "    Vb1 = torch.from_numpy(Vb1)\n",
    "    Vb1.to('cuda')\n",
    "    VW2 = torch.from_numpy(VW2)\n",
    "    VW2.to('cuda')\n",
    "    Vb2 = torch.from_numpy(Vb2)\n",
    "    Vb2.to('cuda')\n",
    "    VW3 = torch.from_numpy(VW3)\n",
    "    VW3.to('cuda')\n",
    "    Vb3 = torch.from_numpy(Vb3)\n",
    "    Vb3.to('cuda')\n",
    "    VW4 = torch.from_numpy(VW4)\n",
    "    VW4.to('cuda')\n",
    "    Vb4 = torch.from_numpy(Vb4)\n",
    "    Vb4.to('cuda')\n",
    "    VW5 = torch.from_numpy(VW5)\n",
    "    VW5.to('cuda')\n",
    "    Vb5 = torch.from_numpy(Vb5)\n",
    "    Vb5.to('cuda')\n",
    "\n",
    "    \n",
    "    for i in range(int(len(train_image_list)/batch_size) - 1):\n",
    "        \n",
    "        tW1, tb1, tW2, tb2, tW3, tb3, tW4, tb4, tW5, tb5 = initialize_weights_and_bias(mode='zero')\n",
    "        tW1 = torch.from_numpy(tW1)\n",
    "        tW1.to('cuda')\n",
    "        tb1 = torch.from_numpy(tb1)\n",
    "        tb1.to('cuda')\n",
    "        tW2 = torch.from_numpy(tW2)\n",
    "        tW2.to('cuda')\n",
    "        tb2 = torch.from_numpy(tb2)\n",
    "        tb2.to('cuda')\n",
    "        tW3 = torch.from_numpy(tW3)\n",
    "        tW3.to('cuda')\n",
    "        tb3 = torch.from_numpy(tb3)\n",
    "        tb3.to('cuda')\n",
    "        tW4 = torch.from_numpy(tW4)\n",
    "        tW4.to('cuda')\n",
    "        tb4 = torch.from_numpy(tb4)\n",
    "        tb4.to('cuda')\n",
    "        tW5 = torch.from_numpy(tW5)\n",
    "        tW5.to('cuda')\n",
    "        tb5 = torch.from_numpy(tb5)\n",
    "        tb5.to('cuda')\n",
    "        \n",
    "\n",
    "\n",
    "        for k in range(batch_size):\n",
    "        \n",
    "            \n",
    "            img = cv2.imread(train_image_list[i * batch_size + k])\n",
    "            x = preprocess_input(img)\n",
    "            y = np.zeros(10)\n",
    "            y[int(target[i * batch_size + k])] = 1\n",
    "            \n",
    "            #network forward pass\n",
    "            z1, z2, z3, z4, y_hat = forward_pass(x, W1, b1, W2, b2, W3, b3, W4, b4, W5, b5)\n",
    "            y_hat = np.array(y_hat)\n",
    "\n",
    "            #the true positives for this case, to calculate accuracy\n",
    "            if np.argmax(y_hat) == np.argmax(y):\n",
    "                tp += 1\n",
    "\n",
    "            #we use categorical cross entropy loss\n",
    "            loss = 0\n",
    "            for i in range(len(y)):\n",
    "                if y[i] != 0:\n",
    "                    loss +=  -y[i] * np.log(y_hat[i])\n",
    "            losss += loss\n",
    "\n",
    "\n",
    "            #network backward pass\n",
    "            dW1, db1, dW2, db2, dW3, db3, dW4, db4, dW5, db5 = backward_pass(x, y, W1, b1, W2, b2, W3, b3, W4, b4, W5, b5, z1, z2, z3, z4, y_hat)\n",
    "\n",
    "\n",
    "            #take average of t-variables\n",
    "            tW1 = torch.add(tW1, dW1)\n",
    "            tb1 = torch.add(tb1, db1)\n",
    "            tW2 = torch.add(tW2, dW2.T)\n",
    "            tb2 = torch.add(tb2, db2)\n",
    "            tW3 = torch.add(tW3, dW3.T)\n",
    "            tb3 = torch.add(tb3, db3)\n",
    "            tW4 = torch.add(tW4, dW4.T)\n",
    "            tb4 = torch.add(tb4, db4)\n",
    "            tW5 = torch.add(tW5, dW5.T)\n",
    "            tb5 = torch.add(tb5, db5)\n",
    "            \n",
    "        #take average\n",
    "        tW1 = tW1/batch_size\n",
    "        tb1 = tb1/batch_size\n",
    "        tW2 = tW2/batch_size\n",
    "        tb2 = tb2/batch_size\n",
    "        tW3 = tW3/batch_size\n",
    "        tb3 = tb3/batch_size\n",
    "        tW4 = tW4/batch_size\n",
    "        tb4 = tb4/batch_size\n",
    "        tW5 = tW5/batch_size\n",
    "        tb5 = tb5/batch_size\n",
    "\n",
    "        #update V weights and bias\n",
    "        VW1 = torch.add(VW1, tW1**2)\n",
    "        Vb1 = torch.add(Vb1, tb1**2)\n",
    "        VW2 = torch.add(VW2, tW2**2)\n",
    "        Vb2 = torch.add(Vb2, tb2**2)\n",
    "        VW3 = torch.add(VW3, tW3**2)\n",
    "        Vb3 = torch.add(Vb3, tb3**2)\n",
    "        VW4 = torch.add(VW4, tW4**2)\n",
    "        Vb4 = torch.add(Vb4, tb4**2)\n",
    "        VW5 = torch.add(VW5, tW5**2)\n",
    "        Vb5 = torch.add(Vb5, tb5**2)\n",
    "\n",
    "        #update weights and bias\n",
    "        W1 = W1 - lr/np.sqrt(VW1+epsilon) * tW1\n",
    "        b1 = b1 - lr/np.sqrt(Vb1+epsilon) * tb1\n",
    "        W2 = W2 - (lr/np.sqrt(VW2+epsilon) * tW2).T\n",
    "        b2 = b2 - lr/np.sqrt(Vb2+epsilon) * tb2\n",
    "        W3 = W3 - (lr/np.sqrt(VW3+epsilon) * tW3).T\n",
    "        b3 = b3 - lr/np.sqrt(Vb3+epsilon) * tb3\n",
    "        W4 = W4 - (lr/np.sqrt(VW4+epsilon) * tW4).T\n",
    "        b4 = b4 - lr/np.sqrt(Vb4+epsilon) * tb4\n",
    "        W5 = W5 - (lr/np.sqrt(VW5+epsilon) * tW5).T\n",
    "        b5 = b5 - lr/np.sqrt(Vb5+epsilon) * tb5\n",
    "\n",
    "    #             print(W1, \"\\n\")\n",
    "\n",
    "    #we append total loss of each epoch to the losses array\n",
    "    losses.append(losss)\n",
    "    print(f\"Epoch = {j}, Accuracy = {tp/len(train_image_list)}, loss= {losss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8fb6bb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# print(losses)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mlosses\u001b[49m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'losses' is not defined"
     ]
    }
   ],
   "source": [
    "# print(losses)\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1c55ad",
   "metadata": {},
   "source": [
    "## Predicting a few cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78c5c926",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mmatshow(img)\n\u001b[0;32m      5\u001b[0m x \u001b[38;5;241m=\u001b[39m preprocess_input(img)\n\u001b[1;32m----> 6\u001b[0m z1, z2, z3, z4, y_hat \u001b[38;5;241m=\u001b[39m forward_pass(x, \u001b[43mW1\u001b[49m, b1, W2, b2, W3, b3, W4, b4, W5, b5)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_labels[entry]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Predicted: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39margmax(y_hat)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'W1' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAECCAYAAAD+eGJTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARC0lEQVR4nO3da4xf877H8c+302lrelN6MYrTok92dqiTiRCCoy7lgVuEU4n0hKTIbkKcBweJ8OSEnGzUI0k3snvY20nVrTY5hyA4DzR6EXo5TncENXqjqhd6m37Pg1k9RvfM9zcz6///r8Xv/Uqa+c/6zvzX97/Kp+vyW79l7i4A+RpRdQMAqkUIAJkjBIDMEQJA5ggBIHOEAJC5SkLAzOaa2adm9lczu6eKHiJm9rmZfWJmH5nZyhr087SZbTOztX2WHWdmb5rZxuLrpJr196CZdRfb8CMzu7LC/k42s3fMbL2ZrTOzO4vltdiGQX8t2YbW6nECZtYm6X8lXSrpK0kfSprn7utb2kjAzD6X1OXu31TdiySZ2QWS9kj6d3f/bbHs3yTtcPeHiyCd5O7/UqP+HpS0x91/X0VPfZlZp6ROd19tZuMlrZJ0jaR/Ug22YdDfDWrBNqxiT+BsSX9198/c/YCk/5B0dQV9/GK4+3uSdhy1+GpJS4rXS9T7H00lBuivNtx9s7uvLl7vlrRB0nTVZBsG/bVEFSEwXdKmPt9/pRZ+4EFySW+Y2SozW1B1MwOY5u6bi9dbJE2rspkBLDSzj4vDhcoOV/oysxmSzpK0QjXchkf1J7VgG3JisH/nu/vfS7pC0u+K3d3a8t5jurqN/35C0mmSZkvaLOmRSruRZGbjJL0g6S5339W3Vodt2E9/LdmGVYRAt6ST+3x/UrGsNty9u/i6TdJL6j2EqZutxbHkkWPKbRX38zPuvtXde9z9sKQ/qOJtaGbt6v0f7E/u/mKxuDbbsL/+WrUNqwiBDyXNMrOZZjZK0j9KWl5BH/0ys7HFyRmZ2VhJl0laG/9WJZZLml+8ni/plQp7+RtH/ucqXKsKt6GZmaSnJG1w90f7lGqxDQfqr1XbsOVXBySpuNSxSFKbpKfd/V9b3sQAzOxU9f7rL0kjJf256v7M7DlJF0maLGmrpAckvSxpqaRTJH0h6QZ3r+Tk3AD9XaTe3ViX9Lmk2/ocf7e6v/MlvS/pE0mHi8X3qfe4u/JtGPQ3Ty3YhpWEAID64MQgkDlCAMgcIQBkjhAAMkcIAJmrNARqPCRXEv2VVef+6tyb1Nr+qt4TqPVfhOivrDr3V+fepBb2V3UIAKhYqcFCZjZX0uPqHfn3pLs/nPh5RiYFekePDp67/+x36j7wK/X5Uv23tbWF9Z6eniH31FfZ/urO3fv9gMMOgeFMDkIIxEaPHh3WDx8+HNYPHjxYav0jRsQ7hqn1p6Q+3/79+8P6pEnxnbTffffdkHvqa8yYMWF93759Yb3ZIVXWQCFQ5nCAyUGAX4EyIfBLmBwEQMLIZq+guNRR9zOxQLbKhMCgJgdx98WSFkucEwDqqMzhQK0nBwEwOGUvEQ5pchD2BJqro6MjrP/www+l3j919SB1dr3s+lPGjRsX1vfs2VPq/UeOjHecDx06VOr9m22gqwOlzgm4++uSXi/zHgCqxYhBIHOEAJA5QgDIHCEAZI4QADJHCACZa/qwYfxk1KhRYT11nX3Xrl1hfai3Ig9V6i7Crq6usP7uu++G9ZUrV4b1yy67LKyn7iIsO44iNQ6g2eMUmoU9ASBzhACQOUIAyBwhAGSOEAAyRwgAmSMEgMwxTqCFDhw4ENbHjx9f6v1T17FT4xRS/Z177rlh/Zlnngnr3377bVifNm1aWD/ttNPCemqcQWo249R8Aan5FOo6DiCFPQEgc4QAkDlCAMgcIQBkjhAAMkcIAJkjBIDMMU6ghVJP5S07L3/qOnjK1KlTw/rFF18c1k855ZSwvnr16rB+9913h/XUOIDUfApjx44N66n5GlLzEaTGWdQVewJA5ggBIHOEAJA5QgDIHCEAZI4QADJHCACZM3dv3crMWreyX6HUfAO7d+8O61OmTAnrixYtCus33XRTWN+0aVNYT40jSCn73ICyym7/qrl7vwMpSg0WMrPPJe2W1CPpkLvHT58AUDuNGDH4D+7+TQPeB0AFOCcAZK5sCLikN8xslZktaERDAFqr7OHA+e7ebWZTJb1pZv/j7u/1/YEiHAgIoKZK7Qm4e3fxdZuklySd3c/PLHb3Lk4aAvU07BAws7FmNv7Ia0mXSVrbqMYAtEaZw4Fpkl4q7uEeKenP7v6fDekK/UrdL59y+eWXh/U5c+aE9W++iS8CXXfddUPuqa+JEyeG9bLX4SdPnlzq/VP11N9PK8fkDMWwQ8DdP5N0ZgN7AVABLhECmSMEgMwRAkDmCAEgc4QAkDlCAMgc8wm0ULPvR+/qigdlLl++PKx3dnaG9WeffTas33zzzWE9JfVcgL1794b1tra2sN7T0zPknoaibP/NNtB8AuwJAJkjBIDMEQJA5ggBIHOEAJA5QgDIHCEAZI5xAjWSuh+9vb09rP/4449hffv27WF9zJgxYf3SSy8N6x9++GFYL2vEiPjfrJEj4zvjDx8+3NR63ecTYJwAgH4RAkDmCAEgc4QAkDlCAMgcIQBkjhAAMteIpxJjkDo6OsL6Dz/8ENaPP/74sL5169aw3t3dHdbnz58f1jdu3BjWU58vJfX5U9fZDxw4ENabfR2/6nEAw8WeAJA5QgDIHCEAZI4QADJHCACZIwSAzBECQOYYJ9BCqevg06dPD+vLli0L66nnBtx6661hff369WE9Nd9A6vOljB49OqynrvPv27cvrKeu46fmI0it/+DBg2G9rpJ7Amb2tJltM7O1fZYdZ2ZvmtnG4uuk5rYJoFkGczjwR0lzj1p2j6S33H2WpLeK7wH8AiVDwN3fk7TjqMVXS1pSvF4i6ZrGtgWgVYZ7YnCau28uXm+RNK1B/QBosdInBt3dowlEzWyBpAVl1wOgOYa7J7DVzDolqfi6baAfdPfF7t7l7vEjcwFUYrghsFzSkftO50t6pTHtAGi15OGAmT0n6SJJk83sK0kPSHpY0lIzu1XSF5JuaGaTubjuuuvC+jnnnBPWX3311bC+atWqsD5hwoSwvmvXrrBedt7//fv3h/WUE088Mazv2HH0+e2hSY1DGDVqVFhPzXdQlWQIuPu8AUpzGtwLgAowbBjIHCEAZI4QADJHCACZIwSAzBECQOaYT6CFxo8fH9YvuOCCsL5z586wftVVV4X1ESPizE9dx0/d75+6zp+ajyAldZ3+66+/LvX+bW1tpX6/ruMAUtgTADJHCACZIwSAzBECQOYIASBzhACQOUIAyBzjBFroxx9/DOupcQTHHntsqfWn5t1PaW9vD+snnXRSWJ85c2ZYT32+iRMnhvXXXnstrKeei5CaLyG1/u+//z6s1xV7AkDmCAEgc4QAkDlCAMgcIQBkjhAAMkcIAJmzsteOh7Sy4HFlOZg79+iHO//csmXLwnrqfvcLL7wwrKfmA+jp6QnrqfkG3njjjbCeGgeRei5AapxCar6FdevWhfWHHnoorH/wwQdhve7zCbi79becPQEgc4QAkDlCAMgcIQBkjhAAMkcIAJkjBIDMMU6ghWbPnh3W16xZU+r99+7dG9bHjh1b6v1TzxXYtGlTWF+4cGFYT81HMGXKlLA+b968sH7qqaeG9WOOOSas33vvvWF90aJFYf3gwYNhvdmGPU7AzJ42s21mtrbPsgfNrNvMPir+XNnIZgG0zmAOB/4oqb+hbo+5++ziz+uNbQtAqyRDwN3fkxSP5wTwi1XmxOBCM/u4OFyY1LCOALTUcEPgCUmnSZotabOkRwb6QTNbYGYrzWzlMNcFoImGFQLuvtXde9z9sKQ/SDo7+NnF7t7l7l3DbRJA8wwrBMyss8+310paO9DPAqi35DgBM3tO0kWSJkvaKumB4vvZklzS55Juc/fNyZVlPk5gzpw5Yf3FF18M6x0dHWE9dR16w4YNYX3p0qWlfv/tt98O63v27Anro0aNCuup+/XN+r0M/v+uuOKKsP7888+H9dQ4iEsuuSSsf/XVV2G92QYaJ5B8+Ii79zcC46nSHQGoBYYNA5kjBIDMEQJA5ggBIHOEAJA5QgDIXPISIRpn/fr1YT31fPsJEyaE9dT99KnnGqR0dnaG9dQ4gJTUOICy4whefz2+2fXTTz8N67NmzQrrM2bMCOtVjxMYCHsCQOYIASBzhACQOUIAyBwhAGSOEAAyRwgAmWOcQAtt3749rH/wwQdh/YQTTgjrc+f2Nyn0T1L3+x86dCisb94cTxnR3t4e1kePHh3WU+MMmj2O4LPPPgvrX375ZVhfsWJFWK8r9gSAzBECQOYIASBzhACQOUIAyBwhAGSOEAAyxziBFkpdh3/88cfD+nnnnRfWb7nllrB+xhlnhPX7778/rK9Zsyasz5w5M6ynnnExYkT8b1LquQs33nhjWD/77AEflCVJOv3008P6okWLwnpqHETquRBVYU8AyBwhAGSOEAAyRwgAmSMEgMwRAkDmCAEgc5a6dtvQlZm1bmU1VPZ+9zPPPDOsp54rkLoOnpKalz/1/m1tbWE99fl37twZ1qdOnRrWU5588smwnhpHsWXLllLrbzZ3t/6WJ/cEzOxkM3vHzNab2Tozu7NYfpyZvWlmG4uvkxrdNIDmG8zhwCFJ/+zuv5F0jqTfmdlvJN0j6S13nyXpreJ7AL8wyRBw983uvrp4vVvSBknTJV0taUnxY0skXdOkHgE00ZBODJrZDElnSVohaZq7H5l0boukaY1tDUArDPoGIjMbJ+kFSXe5+y6zn84xuLsPdNLPzBZIWlC2UQDNMag9ATNrV28A/MndXywWbzWzzqLeKWlbf7/r7ovdvcvduxrRMIDGGszVAZP0lKQN7v5on9JySfOL1/MlvdL49gA0W3KcgJmdL+l9SZ9IOlwsvk+95wWWSjpF0heSbnD3HYn3ynqcQMrYsWNL/f7evXvD+u233x7W77jjjrA+ceLEsP7YY4+F9euvvz6sd3d3h/Vvv/02rG/atKnU+7/88sthfffu3WF95Mj46Do1n0SzDTROIHlOwN3/W1K/vyxpTpmmAFSPYcNA5ggBIHOEAJA5QgDIHCEAZI4QADLHfAK/Iqn79Xt6esJ6e3t7WE/Nm58a55Aax1BW2c+fkhoHkFr//v37S62/rGHPJwDg140QADJHCACZIwSAzBECQOYIASBzhACQOcYJtFDfKdn6k/q7GD9+fFhP3e+euo6dUvY6e2r9HR0dYT31+cqqepxDszFOAEC/CAEgc4QAkDlCAMgcIQBkjhAAMkcIAJljnACQCcYJAOgXIQBkjhAAMkcIAJkjBIDMEQJA5ggBIHPJEDCzk83sHTNbb2brzOzOYvmDZtZtZh8Vf65sfrsAGi05WMjMOiV1uvtqMxsvaZWkayTdIGmPu/9+0CtjsBBQmYEGC8WPVOn9xc2SNhevd5vZBknTG9segKoM6ZyAmc2QdJakFcWihWb2sZk9bWaTGt0cgOYbdAiY2ThJL0i6y913SXpC0mmSZqt3T+GRAX5vgZmtNLOV5dsF0GiDuoHIzNol/UXSf7n7o/3UZ0j6i7v/NvE+nBMAKjLsG4isd4rcpyRt6BsAxQnDI66VtLZskwBabzBXB86X9L6kTyQdLhbfJ2meeg8FXNLnkm4rTiJG78WeAFCRgfYEmE8AyATzCQDoFyEAZI4QADJHCACZIwSAzBECQOYIASBzhACQOUIAyBwhAGSOEAAyRwgAmSMEgMwRAkDmCAEgc8nZhhvsG0lf9Pl+crGsruivnDr3V+fepMb393cDFVo6qcjfrNxspbt3VdZAAv2VU+f+6tyb1Nr+OBwAMkcIAJmrOgQWV7z+FPorp8791bk3qYX9VXpOAED1qt4TAFAxQgDIHCEAZI4QADJHCACZ+z8fy2kESgSO2gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "entry = 12\n",
    "\n",
    "img = cv2.imread(test_image_list[entry])\n",
    "plt.matshow(img)\n",
    "x = preprocess_input(img)\n",
    "z1, z2, z3, z4, y_hat = forward_pass(x, W1, b1, W2, b2, W3, b3, W4, b4, W5, b5)\n",
    "print(f'Actual: {test_labels[entry]} | Predicted: {np.argmax(y_hat)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49a26924",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m y[\u001b[38;5;28mint\u001b[39m(target[i])] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#network forward pass\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m z1, z2, z3, z4, y_hat \u001b[38;5;241m=\u001b[39m forward_pass(x, \u001b[43mW1\u001b[49m, b1, W2, b2, W3, b3, W4, b4, W5, b5)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39margmax(y_hat)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39margmax(y)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39margmax(y_hat) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'W1' is not defined"
     ]
    }
   ],
   "source": [
    "tp_test = 0\n",
    "\n",
    "for i in range(len(test_image_list)):\n",
    "    img = cv2.imread(test_image_list[i])\n",
    "    x = preprocess_input(img)\n",
    "    target = np.array(test_labels)\n",
    "    y = np.zeros(10)\n",
    "    y[int(target[i])] = 1\n",
    "\n",
    "\n",
    "    #network forward pass\n",
    "    z1, z2, z3, z4, y_hat = forward_pass(x, W1, b1, W2, b2, W3, b3, W4, b4, W5, b5)\n",
    "    \n",
    "    print(f\"{np.argmax(y_hat)} \\ {np.argmax(y)}\")\n",
    "    \n",
    "    if np.argmax(y_hat) == np.argmax(y):\n",
    "        tp_test += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "453d2da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test data: 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy for test data: {round(tp_test/len(test_image_list), 2)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dff2c9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8186, 0.8474, 0.8186, 0.6224, 0.8722, 0.5365, 0.5960, 0.9428, 0.5067,\n",
       "         0.7517],\n",
       "        [0.9230, 0.9528, 0.3959, 0.0822, 0.5774, 0.2259, 0.8887, 0.2063, 0.5932,\n",
       "         0.3351],\n",
       "        [0.3279, 0.9969, 0.2091, 0.1342, 0.1416, 0.7302, 0.1122, 0.0821, 0.0373,\n",
       "         0.2927],\n",
       "        [0.8243, 0.8204, 0.0630, 0.3968, 0.7781, 0.4157, 0.6094, 0.8071, 0.4468,\n",
       "         0.0702],\n",
       "        [0.5796, 0.7826, 0.8662, 0.7891, 0.6626, 0.1192, 0.5207, 0.3207, 0.3780,\n",
       "         0.0737],\n",
       "        [0.7809, 0.2107, 0.1117, 0.9956, 0.1900, 0.4084, 0.9949, 0.3198, 0.3403,\n",
       "         0.8416],\n",
       "        [0.0054, 0.2978, 0.5776, 0.2880, 0.1038, 0.2988, 0.3785, 0.3033, 0.5339,\n",
       "         0.7066],\n",
       "        [0.7097, 0.0851, 0.8173, 0.2135, 0.2681, 0.8396, 0.6676, 0.9288, 0.3132,\n",
       "         0.6085],\n",
       "        [0.1717, 0.3140, 0.4043, 0.4423, 0.2600, 0.8239, 0.6270, 0.8363, 0.3644,\n",
       "         0.4972],\n",
       "        [0.1610, 0.7094, 0.5980, 0.0531, 0.7059, 0.1585, 0.2030, 0.8951, 0.9807,\n",
       "         0.8529]], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.random((10, 10)).astype(np.float32)   \n",
    "b = np.random.random((10, 10)).astype(np.float32) \n",
    "a = torch.from_numpy(a)\n",
    "b = torch.from_numpy(b)\n",
    "a.to(device)\n",
    "b.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80aa30fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2901, 2.5699, 2.3186, 1.8370, 2.0899, 2.3405, 2.6674, 2.9569, 2.1063,\n",
       "         2.3469],\n",
       "        [1.8200, 2.9902, 2.5222, 1.5697, 1.9012, 2.2930, 2.1776, 2.5413, 2.1998,\n",
       "         2.5593],\n",
       "        [2.3805, 3.0671, 2.4373, 1.8954, 2.1849, 2.4336, 2.6982, 2.7553, 2.0634,\n",
       "         2.1161],\n",
       "        [3.0936, 3.6794, 2.6601, 2.5433, 2.7209, 2.5706, 3.5667, 3.1914, 2.8055,\n",
       "         2.9419],\n",
       "        [2.9720, 2.8867, 2.9389, 2.4691, 2.4077, 2.0307, 3.2617, 2.8213, 2.6021,\n",
       "         3.0326],\n",
       "        [2.8119, 3.4956, 2.4453, 1.7843, 2.2268, 2.6176, 3.1249, 2.7904, 2.5934,\n",
       "         2.8888],\n",
       "        [3.4391, 4.0759, 3.5708, 2.6409, 3.0802, 3.3143, 3.5122, 4.0961, 3.0895,\n",
       "         3.8262],\n",
       "        [2.6873, 3.3138, 2.0799, 2.1246, 2.0817, 2.4590, 2.8746, 2.4814, 2.1724,\n",
       "         2.8192],\n",
       "        [2.9079, 3.1285, 2.8068, 2.1336, 2.6480, 1.9541, 3.1218, 3.0249, 2.7936,\n",
       "         2.9840],\n",
       "        [2.9987, 3.3417, 2.7557, 2.6123, 2.3947, 2.1973, 3.0011, 2.4961, 2.1736,\n",
       "         2.7123]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1dd67b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6b00b3db7fb76d5530de3dfa8b6a013afe52adf2c8d6882bc84fd35759d781d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
